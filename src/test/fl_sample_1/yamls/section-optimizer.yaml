#-----------------------------
# Optimizer section args
#-----------------------------
optimizer:
  type: SGD             # Options: SGD, Adam, Adagrad, RMSprop, etc.
  lr: 0.01              # Learning rate
  weight_decay: 0.0001  # Weight decay (set to None if not used)
  momentum: 0.9         # Momentum (for SGD and RMSprop, set to None if not used)
  nesterov: False       # Whether to use Nesterov momentum (only applicable for SGD; set to None if not used)
  betas: [0.9, 0.999]   # Betas parameter for Adam (set to None if not used)
  amsgrad: False        # Whether to use AMSGrad (only applicable for Adam; set to None if not used)
  eps: 1e-8             # Epsilon parameter for Adam (set to None if not used)
  alpha: None           # Alpha parameter for RMSprop (set to None if not used)
  centered: None        # Centered parameter for RMSprop (set to None if not used)
